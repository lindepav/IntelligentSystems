---
title: "Assigment 2"
author: "Pavel Linder, Nikita Brancatisano"
date: "12/26/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r libraries, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
#install.packages("ngram")
#install.packages("ggplot2")
library(gtools) # if problems calling library, install.packages("gtools", dependencies = T)

library(stringr)
library(tm) # framework for text mining; it loads NLP package
library(cluster)
library(proxy)
library(ngram)
```

## 0. Read input
```{r import, echo=TRUE}
train = read.table(file = 'train.tsv', sep = '\t', header = TRUE, stringsAsFactors = FALSE)
train.text = read.table(file = 'train.tsv', sep = '\t', header = TRUE, stringsAsFactors = FALSE)

test = read.table(file = 'test.tsv', sep = '\t', header = TRUE)
length(which(!complete.cases(train)))
head(train$text_a)
```



# 1. Cleaning data
## Remove punctuation and stopwords
```{r punctuation, echo=TRUE}
train$text_a = as.character(train$text_a)
train$text_a = tm::removePunctuation(train$text_a)
train$text_a = tm::removeWords(x = train$text_a, stopwords(kind = "SMART"))
train$text_a = tm::stripWhitespace(train$text_a)

word_count <- lapply(train$text_a, wordcount)
length(which(word_count > 100))
length(which(word_count < 100))
length(which(word_count == 0))
length(train$text_a)
train <- train[which(word_count < 100),]
word_count <- lapply(train$text_a, wordcount)
length(train$text_a)
train <- train[which(word_count > 0),]
length(train$text_a)
head(train$text_a)
```

## Anonymize proper nouns

```{r import2, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
#install.packages("rJava")
#install.packages("openNLP")
#install.packages("openNLPmodels.en", dependencies=TRUE, repos = "http://datacube.wu.ac.at/")
library(NLP)
library(rJava)
library(openNLP)
library(openNLPmodels.en)
library(digest)
```

```{r anonymize, echo=TRUE, cache=TRUE}
n <- length(train$text_a)
word_ann <- Maxent_Word_Token_Annotator()
sent_ann <- Maxent_Sent_Token_Annotator()
pos_ann = Maxent_POS_Tag_Annotator()

for (i in 1:n) {
  while(1) {
    doc <- as.String(train$text_a[[i]])
    wordAnnotation <- annotate(doc, list(sent_ann, word_ann))
    POSAnnotation <- annotate(doc, pos_ann, wordAnnotation)
    POSWords <- subset(POSAnnotation, type == "word")  
    POSTags <- vector()
    for (j in 1:length(POSWords$features))
      POSTags <- c(POSTags, POSWords$features[[j]]$POS)
    tokenPOS <- cbind(doc[POSWords], POSTags)
    ppn_idx <- which(tokenPOS[,2] == "NNP", 1)
    if (length(ppn_idx) == 0) {
      break;
    }
    words <- subset(wordAnnotation, type == "word")  
    hashed <- digest(tokenPOS[ppn_idx, 1], "xxhash32")
    ppn <- words[ppn_idx]
    train$text_a[[i]] <- gsub(doc[ppn$start,ppn$end], hashed, doc)
  }
}

head(train$text_a)
n <- length(train$text_a)

```

## Remove unknown symbols (non UTF-8 characters)
```{r symbols, echo=TRUE}
train$text_a <- iconv(train$text_a, to='UTF-8', sub='byte')
length(train$text_a)
head(train$text_a)
```

# 2. Exploration
We are computing the TDM matrix from 2 corpuses: one with stemmization, one without. From the results we can see that the character of the corpus remains. Thus, we will use the stemmed corpus for the future evaluation.

### I. Plot the frequency of words (without stemmization)
```{r frequency1, echo=TRUE}
library(ggplot2)
corpus <- Corpus(VectorSource(train$text_a)) # turn into corpus
tdm <- TermDocumentMatrix(corpus)

wordFreq <- sort(rowSums(as.matrix(tdm)), decreasing=TRUE)
qplot(seq(length(wordFreq)),sort(wordFreq), xlab = "index", ylab = "Frequency")

findFreqTerms(tdm, lowfreq=50)
mostFreq <- subset(wordFreq, wordFreq >= 50)
head(mostFreq, 10)

length(wordFreq)
length(wordFreq[wordFreq<10])
length(wordFreq[wordFreq<5])
length(wordFreq[wordFreq==1])

freq <- sort(unique(wordFreq), decreasing=FALSE)
occ <- vector()
for (i in 1:length(freq)) {
  occ[i] <- length(wordFreq[wordFreq == freq[i]])
}
qplot(freq[1:30], occ[1:30], xlab = "Frequency of word", ylab = "# of occurencies")

```

### II. Plot the frequency of words (with stemmization)
```{r stemmization1, echo=TRUE}
stemmed <- stemDocument(train$text_a, language = "english")
corpus2 <- Corpus(VectorSource(stemmed)) # turn into corpus
```

```{r freq2, echo=FALSE}
tdm2 <- TermDocumentMatrix(corpus2)
wordFreq <- sort(rowSums(as.matrix(tdm2)), decreasing=TRUE)
mostFreq <- subset(wordFreq, wordFreq >= 50)
head(mostFreq, 10)

length(wordFreq)
length(wordFreq[wordFreq<10])
length(wordFreq[wordFreq<5])
length(wordFreq[wordFreq==1])

freq <- sort(unique(wordFreq), decreasing=FALSE)
occ <- vector()
for (i in 1:length(freq)) {
  occ[i] <- length(wordFreq[wordFreq == freq[i]])
}
qplot(freq[1:30], occ[1:30], xlab = "Frequency of word", ylab = "# of occurencies")
```

## II. Perform a clustering on the vectorized document space
We will use Weighted TF-IDF as a way to represent the document space:
```{r cluster1, echo=TRUE}
tdm <- tm::DocumentTermMatrix(corpus2) 
tdm.tfidf <- tm::weightTfIdf(tdm)
tdm.tfidf <- tm::removeSparseTerms(tdm.tfidf, 0.999)  # sparsity being not well handled overall in R
tfidf.matrix <- as.matrix(tdm.tfidf) 
```
Afterwards, we perform k-means algorithm to cluster in {2,4,8,16} classes.
```{r cluster2, echo=TRUE}
cluster2 <- kmeans(tfidf.matrix, centers=2)
cluster4 <- kmeans(tfidf.matrix, centers=4)
cluster8 <- kmeans(tfidf.matrix, centers=8)
cluster16 <- kmeans(tfidf.matrix, centers=16)

cluster2.master <- cluster2$cluster
cluster4.master <- cluster4$cluster
cluster8.master <- cluster8$cluster
cluster16.master <- cluster16$cluster
```

We perform Classical multidimensional scaling (SMC) to map the data (distance matrix) into 2D dimension and then visualize it.
```{r cluster_visualize, echo=TRUE, cache=TRUE}
dist.matrix = proxy::dist(tfidf.matrix, method = "cosine") 
points <- cmdscale(dist.matrix, k = 2) 
previous.par <- par(mfrow=c(2,2), mar = rep(1.5, 4)) 
color <- grDevices::colors()[grep('gr(a|e)y', grDevices::colors(), invert = T)]

my_palette = sample(color, 2)
plot(points, main = 'K-Means clustering (k=2)', col = my_palette[as.factor(cluster2.master)], 
     mai = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), 
     xaxt = 'n', yaxt = 'n', xlab = '', ylab = '') 
legend("topright", sprintf("%s",seq(1,2)), fill = my_palette[1:2])
clusplot(points, cluster2.master, main='K-Means clustering (k=2)', color=TRUE, shade=TRUE, labels=5, lines=0, span = TRUE, stand=TRUE)

my_palette = sample(color, 4)
plot(points, main = 'K-Means clustering (k=4)', col = my_palette[as.factor(cluster4.master)], 
     mai = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), 
     xaxt = 'n', yaxt = 'n', xlab = '', ylab = '') 
legend("topright", sprintf("%s",seq(1,4)), fill = my_palette[1:4])
clusplot(points, cluster4.master, main = 'K-Means clustering (k=4)', color=TRUE, shade=TRUE, labels=5, lines=0, span = TRUE)

my_palette = sample(color, 8)
plot(points, main = 'K-Means clustering (k=8)', col = my_palette[as.factor(cluster8.master)], 
     mai = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), 
     xaxt = 'n', yaxt = 'n', xlab = '', ylab = '') 
legend("topright", sprintf("%s",seq(1,8)), fill = my_palette[1:8])
clusplot(points, cluster8.master, main = 'K-Means clustering (k=8)', color=TRUE, shade=TRUE, labels=5, lines=0, span = TRUE)

my_palette = sample(color, 16)
plot(points, main = 'K-Means clustering (k=16)', col = my_palette[as.factor(cluster16.master)],  
     mai = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), 
     xaxt = 'n', yaxt = 'n', xlab = '', ylab = '') 
legend("topright", sprintf("%s",seq(1,16)), fill = my_palette[1:16])
clusplot(points, cluster16.master, main = 'K-Means clustering (k=16)', color=TRUE, shade=TRUE, labels=5, lines=0, span = TRUE)

par(previous.par) # recovering the original plot space parameters 
```

```{r class_coloring, echo=TRUE}
points <- cmdscale(dist.matrix, k = 2) 
colors <- c('red', 'blue')

plot(points, main = 'Documents with class labels', col = colors[as.factor(train$label)], 
     mai = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), 
     xaxt = 'n', yaxt = 'n', xlab = '', ylab = '') 
legend("topright", c('ham', 'insult'), fill = colors[1:2])
```

```{r import3, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
#install.packages("openNLPmodels.en", dependencies=TRUE, repos = "http://datacube.wu.ac.at/")
library(NLP)
library(rJava)
library(openNLP)
library(openNLPmodels.en)
library(purrr)
detach("package:ggplot2", unload=TRUE)
```

```{r pos, echo=TRUE, cache=TRUE}
stemmed <- stemDocument(train$text_a, language = "english")
docs <- stemmed
n <- length(docs)
word_ann <- Maxent_Word_Token_Annotator()
sent_ann <- Maxent_Sent_Token_Annotator()
pos_ann = Maxent_POS_Tag_Annotator()

docsPOS <- list()
for (i in 1:n) {
  doc <-  as.String(docs[[i]])
  wordAnnotation <- annotate(doc, list(sent_ann, word_ann))
  POSAnnotation <- annotate(doc, pos_ann, wordAnnotation)
  POSWords <- subset(POSAnnotation, type == "word")  
  POSTags <- vector()
  for (j in 1:length(POSWords$features))
    POSTags <- c(POSTags, POSWords$features[[j]]$POS)
  docsPOS[[i]] <- list(POSTags)
}

for(i in 1:length(docsPOS)){
  docsPOS[i] = flatten(docsPOS[i])
  docsPOS[[i]] = paste(docsPOS[[i]], collapse=" ")
}

head(docsPOS)
head(stemmed)    
length(docsPOS)

docsPOS <- matrix(docsPOS, 801, 1)
docsPOS <- unlist(docsPOS)
trainPOS <- train
textPOS <- trainPOS$text_a
textPOS <- paste(textPOS, docsPOS)
trainPOS$text_a <- textPOS
stemmedPOS <- stemDocument(trainPOS$text_a, language = "english")

head(stemmedPOS)
```

# 3. Modeling
```{r preprocess_test, echo=TRUE, cache=TRUE}
test$text_a = as.character(test$text_a)
test$text_a = tm::removePunctuation(test$text_a)
test$text_a = tm::removeWords(x = test$text_a, stopwords(kind = "SMART"))
test$text_a = tm::stripWhitespace(test$text_a)

test <- test[which(lapply(test$text_a, wordcount) > 0),]
n <- length(test$text_a)
for (i in 1:n) {
  while(1) {
    doc <- as.String(test$text_a[[i]])
    wordAnnotation <- annotate(doc, list(sent_ann, word_ann))
    POSAnnotation <- annotate(doc, pos_ann, wordAnnotation)
    POSWords <- subset(POSAnnotation, type == "word")
    POSTags <- vector()
    for (j in 1:length(POSWords$features))
      POSTags <- c(POSTags, POSWords$features[[j]]$POS)
    tokenPOS <- cbind(doc[POSWords], POSTags)
    ppn_idx <- which(tokenPOS[,2] == "NNP", 1)
    if (length(ppn_idx) == 0) {
      break;
    }
    words <- subset(wordAnnotation, type == "word")
    hashed <- digest(tokenPOS[ppn_idx, 1], "xxhash32")
    ppn <- words[ppn_idx]
    test$text_a[[i]] <- gsub(doc[ppn$start,ppn$end], hashed, doc)
  }
}
test$text_a <- iconv(test$text_a, to='UTF-8', sub='byte')
test$label=ifelse(test$label==0,"No","Yes") 
test$label <- as.factor(test$label)
stemmedtest <- stemDocument(test$text_a, language = "english")
corpustest <- Corpus(VectorSource(stemmedtest)) # turn into corpus

tdmtest <- tm::DocumentTermMatrix(corpustest) 
tdmtest.tfidf <- tm::weightTfIdf(tdmtest)
tdmtest.tfidf <- tm::removeSparseTerms(tdmtest.tfidf, 0.999) 
tfidftest.matrix <- as.matrix(tdmtest.tfidf)
```

```{r import4, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
#install.packages("ipred")
#install.packages("MLmetrics")
library(ipred)
library(caret)
library(tm)
library(MLmetrics)
library(rpart)
library(rpart.plot)
library(ROSE)
```

#The train dataset is imbalanced with, where there are more than 2 times as much documents labeled as non-insults than insults. We performed oversampling to get rid of this imbalance:
```{r analyze, echo=TRUE}
train$text_a = stemmed
trainPOS$text_a = stemmedPOS

table(train$label)
trainSVM <- ovun.sample(label ~ ., data = train, method = "over")$data
trainRf <- train[sample(nrow(train), 100), ]
trainRf <- ovun.sample(label ~ ., data = trainRf, method = "over", 150)$data
trainPOS <- ovun.sample(label ~ ., data = trainPOS, method = "over")$data

print('SVM Model:')
table(trainSVM$label)
print('RF Model:')
table(trainRf$label)
print('SVM with Tags Model:')
table(trainPOS$label)
```

```{r model_functions, echo=TRUE, results='hide'}
clean_test <- function(data) {
  test.matrix <- as.data.frame(tfidftest.matrix)
  cols <- colnames(data)
  Missing <- setdiff(cols, names(test.matrix))
  test.matrix[Missing] <- 0
  test.matrix <- test.matrix[cols]
  return(test.matrix)
}

create_model_data <- function(matrix, avect) {
  result <- cbind(matrix, avect)
  result <- as.data.frame(result) 
  result$lbl=ifelse(result$lbl==0,"No","Yes") 
  
  # Adding a vector of labels to the tfidf matrix changing the 0s to No and 1s to Yes  
  result$lbl <- as.factor(result$lbl) 
  return(result)
}
```

```{r undersampling-tfidf, echo=TRUE, results='hide'}
corpus <- Corpus(VectorSource(trainRf$text_a)) # turn into corpus
tdm <- tm::DocumentTermMatrix(corpus) 
tdm.tfidf <- tm::weightTfIdf(tdm)
tdm.tfidf <- tm::removeSparseTerms(tdm.tfidf, 0.999)  # sparsity being not well handled overall in R
tfidf.matrixRf <- as.matrix(tdm.tfidf) 

corpus <- Corpus(VectorSource(trainSVM$text_a)) # turn into corpus
tdm <- tm::DocumentTermMatrix(corpus) 
tdm.tfidf <- tm::weightTfIdf(tdm)
tdm.tfidf <- tm::removeSparseTerms(tdm.tfidf, 0.999)  # sparsity being not well handled overall in R
tfidf.matrixSVM <- as.matrix(tdm.tfidf) 

corpus <- Corpus(VectorSource(trainPOS$text_a)) # turn into corpus
tdmPOS <- tm::DocumentTermMatrix(corpus) 
tdmPOS.tfidf <- tm::weightTfIdf(tdmPOS)
tdmPOS.tfidf <- tm::removeSparseTerms(tdmPOS.tfidf, 0.999)  # sparsity being not well handled overall in R
tfidf.matrixPOS <- as.matrix(tdmPOS.tfidf) 
```

```{r model, echo = TRUE, cache=TRUE}
trainRf$lbl <- trainRf$label
trainSVM$lbl <- trainSVM$label
trainPOS$lbl <- trainPOS$label
avectorRf <- as.vector(trainRf['lbl'])
avectorSVM <- as.vector(trainSVM['lbl'])
avectorPOS <- as.vector(trainPOS['lbl'])

finalRf <- create_model_data(tfidf.matrixRf, avectorRf)
finalSVM <- create_model_data(tfidf.matrixSVM, avectorSVM)
finalPOS <- create_model_data(tfidf.matrixPOS, avectorPOS)

dat <- twoClassSim(200) #A custom f1 funtion for the metric
f1 <- function(data, lev = NULL, model = NULL) {
  f1_val <- F1_Score(y_pred = data$pred, y_true = data$obs, positive = lev[1])
  c(F1 = f1_val)
}
train.control <- trainControl(method = "repeatedcv",
                          number = 5,
                          repeats = 3,
                          classProbs = TRUE,
                          summaryFunction = f1,
                          search = "grid")

fitRf <- caret::train(lbl ~ ., data = finalRf, method = 'rf',tuneLength = 5, metric = "F1",
             trControl = train.control)
fitSvm <- caret::train(lbl ~ ., data = finalSVM, method = 'svmLinear', scale=F, tuneLength = 5, metric = "F1", trControl=train.control) 
fitSvmPOS <- caret::train(lbl ~ ., data = finalPOS, method = 'svmLinear', scale=F, tuneLength = 5, metric = "F1", trControl=train.control) 

print(fitRf$results)
print(fitSvm$results)
print(fitSvmPOS$results)

#We check what columns are missing in the test dataframe and we add them setting their values to 0
test.matrixRf <- clean_test(finalRf)
test.matrixSVM <- clean_test(finalSVM)
test.matrixPOS <- clean_test(finalPOS)

#We predict the two models on the test matrix
predRf = predict(fitRf, newdata=test.matrixRf)
predSvm = predict(fitSvm, newdata=test.matrixSVM)
predSvmPOS = predict(fitSvmPOS, newdata=test.matrixPOS)

#And then we factorize the labels for visualization
con.matrix.rf<-confusionMatrix(predRf, test$label)
con.matrix.svm<-confusionMatrix(predSvm, test$label)
con.matrix.svm.pos<-confusionMatrix(predSvmPOS, test$label)
print(con.matrix.rf)
print(con.matrix.svm)
print(con.matrix.svm.pos)

roc.curve(test$label, predRf, main="RF - ROC curve")
roc.curve(test$label, predSvm, main="SVM - ROC curve")
roc.curve(test$label, predSvm, main="SVM with POS tags - ROC curve")

table(train$label)
table(test$label)
majority_classifier <- length(which(test$label == 'No')) / length(test$label)
majority_classifier
```

# 4. Understanding
```{r feature-selection-preprocess, echo=TRUE}
corpus <- Corpus(VectorSource(stemmed)) # turn into corpus
tdm <- tm::DocumentTermMatrix(corpus) 
tdm.tfidf <- tm::weightTfIdf(tdm)
tdm.tfidf <- tm::removeSparseTerms(tdm.tfidf, 0.999)  # sparsity being not well handled overall in R
tfidf.matrix <- as.matrix(tdm.tfidf) 
```

We will use only terms which occur in more than one document:  
```{r filtering, echo=TRUE}
# load the library
library(mlbench)
library(caret)

# get rid of words which are only in 1 document
dim(tfidf.matrix)
tfidf.matrix <- tfidf.matrix[,-which(rowSums(as.matrix(tdm2)) == 1)]
dim(tfidf.matrix)
```

## Perform feature ranking 
We will use the TF-IDF matrix to calculate information gain by filter method:
```{r feature-selection, echo=TRUE, warning=FALSE}
#install.packages('ggpubr')
library(mlr)
library(ggpubr)
train$lbl <- train$label
avector <- as.vector(train['lbl'])
final <- cbind(tfidf.matrix, avector)
final <- as.data.frame(final) 
final$lbl=ifelse(final$lbl==0,"No","Yes") 
final$lbl <- as.factor(final$lbl)
colnames(final) <- make.names(colnames(final),unique = T)
label.task <- makeClassifTask(data=final, target='lbl')

melt <- reshape2::melt
fv = generateFilterValuesData(label.task, method ="anova.test")

fv$data <- fv$data[order(-fv$data$value),]
fv.plot <- fv
fv.plot$data <- head(fv.plot$data, 20)
plotFilterValues(fv.plot)
```

## Re-evaluate the models performance for top n features 
```{r nfeatures-model, echo=TRUE}
features <- fv$data$name
n_features <- c(head(features, 20), 'lbl')
train.dataSVM <- finalSVM[,n_features]
train.dataRf <- finalRf[,n_features]

fitSvm <- caret::train(lbl ~ ., data = train.dataSVM, method = 'svmLinear',scale=F, tuneLength = 5, metric = "F1",
             trControl = train.control) 
fitRf <- caret::train(lbl ~ ., data = train.dataRf, method = 'rf',tuneLength = 5, metric = "F1",
             trControl = train.control)
fitSvm$results
fitRf$results

test.matrixRf <- clean_test(train.dataRf)
test.matrixSVM <- clean_test(train.dataSVM)

#We predict the two models on the test matrix
predRf = predict(fitRf, newdata=test.matrixRf)
predSvm = predict(fitSvm, newdata=test.matrix)

#And then we factorize the labels for visualization
con.matrix.rf2<-confusionMatrix(predRf, test$label)
con.matrix.svm2<-confusionMatrix(predSvm, test$label)
print(con.matrix.rf2$overall)
print(con.matrix.svm2$overall)
print(con.matrix.rf$overall)
print(con.matrix.svm$overall)
```
## Visualize model performance w.r.t. n by using the selected measure of performance.
```{r nfeatures-visualize, echo=TRUE}
library(ggplot2)
features <- fv$data$name
n <- c(seq(10, 50, 10), 100, 200, 500)
accs <- c()
for (i in 1:length(n)) {
  n_features <- c(head(features, n[i]), 'lbl')
  train.data <- final[,n_features]
  
  fitSvm <- caret::train(lbl ~ ., data = train.data, method = 'svmLinear',scale=F, tuneLength = 5, metric = "F1",
               trControl = train.control) 

  #We check what columns are missing in the test dataframe and we add them setting their values to 0
  test.matrix <- as.data.frame(tfidftest.matrix)
  cols <- colnames(final)
  Missing <- setdiff(cols, names(test.matrix))
  test.matrix[Missing] <- 0
  test.matrix <- test.matrix[cols]
  
  #We predict the two models on the test matrix
  predSvm = predict(fitSvm, newdata=test.matrix)
  
  #And then we factorize the labels for visualization
  con.matrix.svm<-confusionMatrix(predSvm, test$label)
  accs <- c(accs, con.matrix.svm$overall[[1]])
}
qplot(n[1:length(accs)], accs, geom=c("point", "line"))

```

## Extract feature importances from a wrapper method

```{r varimp, echo=TRUE}
# training the model
model <- caret::train(lbl ~ ., data = final, method = 'svmLinear', scale=F, tuneLength = 5, metric = "F1", trControl=train.control) # estimating variable importance
importance <- varImp(model, scale=FALSE)$importance

plot(varImp(model, scale=FALSE), top = 20)
```

## Compare the two feature rankings 

```{r jaccard, echo=TRUE}
library(ggplot2)
get_jaccard <- function(A, B) {
  return(length(intersect(A,B)) / length(union(A,B)))  
}

A <- fv$data$name
B <- rownames(importance[order(-importance$Yes),])
length(A) == length(B)

Jaccard.score <- c()
for (i in 1:length(A)) {
  Jaccard.score[i] <- get_jaccard(A[1:i], B[1:i])
}
n <- seq(1, length(A), 1)
qplot(n, Jaccard.score)

```