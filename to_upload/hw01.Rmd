---
title: "Assigment1"
author: "Pavel Linder, Nikita Brancatisano"
date: "11/6/2019"
output:
  html_document:
    df_print: paged
---

## Installing packages

```{r lib, echo=FALSE}
library("plot3D")
library(caret)

library("GA")
library(corrplot)
library("dplyr")
```


## What does it mean for a function to be non-convex?

A function is non-convex (or concave) if it is a continuous function whose value at the midpoint of every interval in its domain does not exceed the arithmetic mean of its values at the ends of the interval.

# Task 1: Maximization of a non-convex function.
# 1. Code a method f(x, y) that computes a value z, given an input tuple (x, y).
```{r func, echo=TRUE}
f <- function(x, y)  {
  z <- ((1 - x)^2) + (exp(1) * (y - (x^2))^2)
}

```

# 2. Code a method that visualizes the Rosenbrock function in 3D
```{r rosenbrock, echo=TRUE}
x <- y <- seq(-1, 1, length= 20)
z <- outer(x, y, f)
z[is.na(z)] <- 1 # change non-defined elements to 1
persp(x, y, z, theta = 30, phi = 20)
```

# 3. Code a genetic algorithm, that attempts to find the global maximum of this function. 
Here, we tried several crossover method and then selected the best one.
```{r crossover, echo=TRUE}
#We select a list of crossovers
crossovers = c("ga_spCrossover", 
              "gabin_spCrossover", "gabin_uCrossover",
              "gareal_spCrossover", "gareal_waCrossover", "gareal_laCrossover", "gareal_blxCrossover", "gareal_laplaceCrossover",
              "gaperm_cxCrossover", "gaperm_pmxCrossover", "gaperm_pmxCrossover"
        )

```

```{r ga, echo=TRUE}
results = c()
idx <- 0
name <- 0
best <- 0
#We train them all and then we select the best
for (i in 1:length(crossovers)) {
  GA <- ga(type = "real-valued", 
           fitness =  function(x) f(x[1], x[2]),
           lower = c(-1, -1), upper = c(1, 1), 
           popSize = 50, maxiter = 1000, run = 100,
           crossover = crossovers[i]
           )
  if (best < GA@fitnessValue) {
    idx <- i
    best <- GA@fitnessValue
  }
  results[i] <- GA@solution
}
```

```{r summary, echo = T}
solution = results[idx]
plot(GA)
summary(GA)
max_x = as.vector(GA@solution[,1])
max_y = as.vector(GA@solution[,2])
max_z = as.vector(f(GA@solution[,1], GA@solution[,2]))
{res <- persp(x = x, y = x, z = z,theta = 30, phi = 25)
points(trans3d(max_x, max_y, max_z, pmat=res))}
```
```{r history, echo=T}

# BONUS: Plot the trace of evolution
history_x = c()
history_y = c()

for (i in 1:12) {
    GA2 <- ga(type = "real-valued", 
              fitness =  function(x) f(x[1], x[2]),
              lower = c(-1, -1), upper = c(1, 1), 
              popSize = 50, maxiter = 50*i, run = 100)
    history_x[i] <- GA2@solution[,1]
    history_y[i] <- GA2@solution[,2]
    
}	

{res2 <- persp(x=x, y = y, z = z,theta = 30, phi = 25)
points(trans3d(x = history_x, y =history_y , z = f(history_x, history_y), pmat = res))
}
```


## 4. Discuss the results. 
# How does performance vary when you are increasing the number of iterations?
The performance is slowed down because the GA reaches the maximum solution before we run all of the iterations, thus
increasing the number would only slow down the search without providing any significant benefit.

```{r iterations, echo=TRUE}
plot(GA2)
```

# What about population size?
Increasing the population size actually speeds up the process but there's a diminishing return on how much we can increase the population. After a certain amount (depending on the problem) increasing it just slows down the GA.
```{r size, echo=TRUE}

time = c()
size = c()
```
```{r gen, echo=TRUE}
for (i in 1:50) {
    ptm <- proc.time()
    GA3 <- ga(type = "real-valued", 
              fitness =  function(x) f(x[1], x[2]),
              lower = c(-1, -1), upper = c(1, 1), 
              popSize = i*5, maxiter = 30, run = 100)
    time[i] <- proc.time() - ptm
    size[i] = i*5
}
```
```{r genplot, echo=TRUE}
plot(size, time)
```
# Explain the difference between local and global maxima.
A local maxima is the biggest element for one given subset of the whole function. There can still be other values greater than
this one, outside ofthe range of the subset. The global maximum is the largest overall value of the function.


## Task 2: Genetic feature selection
# 1) Read in the dataset 
```{r import, echo=F}
genes <- read.csv("DLBCL.csv")
target <- genes$class
```

# 2) Split the data into training and test sets
```{r splitting, echo=TRUE}
splited <- createDataPartition(
  y = target,
  p = .8,
  list = FALSE
)

learn = genes[ splited, ]
test = genes[-splited, ]

learn$X <- NULL
test$X <- NULL
```

# 3) Build a model using the training set 
```{r training, echo=TRUE}

ctrl <- trainControl(number = 3,
                     method = "repeatedcv")
                     
PLSModel <- train(
  class ~ .,
  data = learn,
  method = "pls",
  preProc = c("center", "scale"),
  trControl = ctrl,
  tuneLenght = 1000
)

           

RFModel <- train(
  class ~ .,   
  data = learn,
  method = "rf",
  preProc = c("center", "scale"),
  trControl = ctrl,
  tuneLenght = 1000
)

           

xgbModel <- train(
  class ~ .,   
  data = learn,
  method = "xgbDART",
  preProc = c("center", "scale"),
  trControl = ctrl,
  tuneLenght = 100
)


SVMModel <- train(
  class ~ .,   
  data = learn,
  method = "svmRadial",
  preProc = c("center", "scale"),
  trControl = ctrl,
  tuneLenght = 1000
)

models_compare <- resamples(list(RF=RFModel, XGBDART=xgbModel, PLS=PLSModel, SVM=SVMModel))

summary(models_compare)

varimp <- varImp(RFModel)
imp <- varimp$importance

plot(varimp, top = 15)
```
# 4) Evaluate the model using the test set 
```{r eval, echo=TRUE}
plsClasses <- predict(xgbModel, newdata = test)
str(plsClasses)

plsProbs <- predict(xgbModel, newdata = test, type = "prob")
head(plsProbs)

confusionMatrix(data = plsClasses, test$class)
```

# Discussing the results 
# Was the feature selection successful? Report how many features were needed for the final performance. Plot the trace of evolution and comment on the change of fitness through generations.
From the plot we can see that the accuracy within the subsets with more than 30 features is not increasing anymore.
```{r number, echo=TRUE}
control <- rfeControl(functions = rfFuncs,
                   method = "repeatedcv",
                   number = 3,
                   verbose = FALSE)
outcomeName <- 'class'
predictors <- names(learn)[!names(learn) %in% outcomeName]
results <- rfe(learn[,predictors], learn[,outcomeName], rfeControl=control, 
               sizes = c(1, 2, 4, 6, 8, 12, 16, 20, 32, 64, 128, 256, 512, 1000))
results

predictors(results)
plot(results)
```
# Suggest how to improve the selection process.
We could use variables thar have a high influence of the class instead of selecting random ones

# The procedure might overfit the data set. How would you prevent it?
We would just run different tests with different ammounts of features and test cases and then we would test the results
to see which quantity is actually the best one

# What are some of the key properties of the fitness function?
The fitness function represent the number of successes while testing our classifier. The more successes we have the more our function fits the model

# Compare the final result (set of features) with the same number of features, that correlate the most with the target variable
```{r cor, echo=TRUE}
result <- genes[, predictors(results)] 

topCor <- data.frame(imp)
topCor$Vars <- row.names(topCor)
topCor <- topCor[order(-topCor$Overall),][1:20,]$Vars
cors <- genes[, topCor]

correlation <- head(round(cor(result, cors),2))
correlation

corrplot(correlation, method="color")
```







